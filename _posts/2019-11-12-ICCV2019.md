---

title: ICCV19 Experiences

published: True

tags: [research, experiences]

---

  

<style>

* {

box-sizing: border-box;

}

  

.column {

float: left;

width: 33.33%;

padding: 5px;

}

  

/* Clearfix (clear floats) */

.row::after {

content: "";

clear: both;

display: table;

}

</style>

With the fast-paced advancements in the machine learning community, conferences have become the frontier of the field. Unlike many other mature science disciplines, most of the research in machine learning is presented at these conferences. Therefore, attending these conferences has become a very valuable activity. Attending ML conferences is so valuable that it is hard to get tickets if you do not book them early on. For instance, [NIPS18 sold-out in 18 minutes]([https://medium.com/syncedreview/nips-tickets-sell-out-in-less-than-12-minutes-e3aab37ab36a](https://medium.com/syncedreview/nips-tickets-sell-out-in-less-than-12-minutes-e3aab37ab36a)) and almost every other conference of the field is witnessing huge growth in both the number of submitted papers and attendees [36, 37]. International Conference on Computer Vision (ICCV) is one such prestigious venue for both deep learning and computer vision. Fortunately, [ICCV19](http://iccv2019.thecvf.com/) was being held in Seoul last week and it was a good opportunity for me since my university is near Seoul. Thanks to my supervisor, [Dr. Sung-Ho Bae](https://sites.google.com/site/sunghobaecv/), I attended it. I had an amazing seven days of experience attending workshops, tutorials, oral and poster presentations, intermingling with researchers, hearing and understanding great ideas of the field, and much much more. In this post, I will share my first-ever experience of attending a big science conference.

  

  

![enter image description here](https://lh3.googleusercontent.com/HCCrMOiaoJYluGJAPLUCmqytmUsUjILqs_e13KXd6QXwWbfYViOs8npGFRbObBnXNcNB35aP6PI)

  


  

  

## Workshops and Tutorials

  

The conference was scheduled to have workshops and tutorials on one first two and last day. All the paper presentations (oral+poster) were sandwiched in between. On the first day, I attended two different talks from [Workshop on statistical deep learning]([http://www.sdlcv-workshop.com/](http://www.sdlcv-workshop.com/)) and [robust subspace leanring]([https://rsl-cv.univ-lr.fr/2019/](https://rsl-cv.univ-lr.fr/2019/)). The first [talk](http://www.sdlcv-workshop.com/slides/talk_WuKorea1.pdf) was on the matrix and vector representation in Neuroscience by [Prof. Ying Nian Wu](http://www.stat.ucla.edu/~ywu/).

The main theme of the talk was around the place and grid cells in the brain of mammalian that are responsible for navigation [1]. The place cells fire only when we encounter a specific place while the grid makes certain hexagonal firing patterns. These neurons are responsible for path planning, and motion and are even called our GPS because of their assistance in navigation even in the absence of visual clues. This paper [1] showed that the self-location of an agent can be represented by a vector and self-displacement with a matrix in higher dimensions in such a way that path planning, displacement, and many other activities can be represented as transformations on these cells. They even showed that hexagonal patterns that emerged from these cells can also be recovered via these higher dimensional representations.

The second talk was on Tensor factorization for robust learning by Jean Kossaifi which was based on [2]. The talk was around the theme of the use of tensor decomposition in deep neural networks which decreases computation complexity and increases robustness. The showed representing the whole neural network with a higher dimensional tensor makes it lightweight, and more robust while maintaining accuracy. Jean Kossaifi is also the author of a famous python library for this purpose called [Tensorly](http://tensorly.org/)

  

In the second half of this day, I attended the tutorial on [interpretation of Deep learning](https://interpretablevision.github.io/) which was jam-packed similar to its predecessor in CVPR19.

  

![](https://interpretablevision.github.io/figures/iccv19_meeting.jpg)

  

  

The first talk of this tutorial was on [Understanding models via visualizations and attribution](https://interpretablevision.github.io/slide/iccv19_vedaldi_slide.pdf) by [Andrea Veladi]([http://www.robots.ox.ac.uk/~vedaldi/](http://www.robots.ox.ac.uk/~vedaldi/)). We know that despite the impressive performance, deep neural networks are black boxes and understanding is very important. We can divide understanding them into three parts; what does a network do, how does it do it and how does it learn? This talk was on the second aspect i.e. how a network does a specific task. And this talk was revolving around two central questions; what does an intermediate layer of DNN know about the input and what does a neural network see in the input image?

*First Question*: What a model knows of input image $x$ at an intermediate layer $y$, as shown in the following figure.

![](https://lh3.googleusercontent.com/E1OAdYaxnHR9VSJE22DQ_Hrcn0zDZaljyMgSzQy8R4tefreBd6cooJU4YQFVr4DZM72FZlx7m-0)

  

One way to answer this question is to project $y$ on input space and get $x_0$. This can be done by simple reconstruction i.e. start from a random initialization of $x_0$ and minizine ![](https://lh3.googleusercontent.com/mnYN08tdpowKP9BCbYDFyZ00gnMtm8fV_IPak41ETaJWfMrMRd-nQ3PjE-ngEqWp8sen8eV8zwQu)
 and get the so-called pre-image or $x_0$. This reconstruction is done without any training data. There are several ways to reconstruct this pre-image such as presented by [3,4,5]. Interestingly, reconstruction from any layer shows a striking similarity to its input. Even the last fully connected layer, despite having only information on output probabilities, do show similarity with the input image.

  

![enter image description here](https://lh3.googleusercontent.com/HdTi6nI7izhpCNIGuVPHJ0UDVetch85RkAFxLY25WSZG1nRktAfD1hZERQme0ufDhn8u9bqFiPs)

  

The deep image prior [4] has previously shown a very interesting result that we can fit a neural network with a single image and can perform many tasks. If we fit a neural network with a single image and then ask the above-mentioned question from this neural network, it still gives a very clear reconstruction of the input image. This is interesting because the neural network is not trained on any data. For an interesting discussion on this topic, see [this](https://distill.pub/2018/building-blocks/)

*Question 2* What does a neural network see in the input image. One straightforward way to answer this question is by visualizing gradients of a network w.r.t to its input image [6,7,8].

  

![enter image description here](https://lh3.googleusercontent.com/LVVJMwmgJnmkFjsyoqODc0EzRkdMORCKH3xQ_HXjO0kc-i3xvPRcHstapyCF-NDv1OiSZqySrso)

  

These visualizations do give some hints but they are not very clear. This problem can be solved by smoothing gradients [9]. But, all of these visualization methods have a problem of channel specificity i.e. changing output class does not change visualization.

![](https://lh3.googleusercontent.com/Vjfu-y96okYLdlUTAGTZNEbxA7RX00KpdAald1HOdVE1jegnpRecd7DUO3rKm9qoTZts82SXyII)

  

This problem can be solved with CAM and GradCAM [9,10] where we use an intermediate layer to see prominent parts of the input image.

One question that is worth asking is what these visualizations mean. Andrew argued that gradient can be thought of as a local linear approximation of the model so we can think of gradient-based visualizations as a sensitivity analysis. This is where new work on perturbation analysis [12] from him and his co-authors comes along which is to understand neural networks via interesting perturbations i.e. by injecting noise, rotation, erasing parts of the input, etc., and see network behavior.

  

![](https://lh3.googleusercontent.com/xwGC_5cqRysKmcU1p6odc0cxizzh58T9RakYICITzbJZQmOOwVUTnE-TIScMdbTjb01a5T1_DqI)

  

This analysis gives several interesting results such as foreground might be sufficient but eliminating background can negatively affect the network, and many more.

  

The second talk was delivered by [Bolei Zhou](http://bzhou.ie.cuhk.edu.hk/) on understanding the latent semantics of GAN. In the last some years, GANs have become better at producing high-quality, realistic, and diverse images. This talk was on understanding this generation process. The talk revolved around three things; the understanding role of neurons, semantics in latent space, and biases and limitations.

  

The first question was on the role of individual neurons in image generation. GAN dissection paper [13] solved this riddle by turning on-off individual neurons and then using semantic segmentation to find the effect of it on generated images. Interestingly, they found that different neurons are responsible for different kinds of objects and scenes in a GAN. For instance, one can find a neuron that is responsible to generate trees in a scene, and then by turning this neuron off or on, one can include/exclude these objects. The following figure shows the effect of different units. You can try a demo of it [here](ganpaint.io).

  

![](https://lh3.googleusercontent.com/Q4kHb4eT0nEajX3t9l7xiGHbfzy57sLZMXkLUoTTkMnEqqEbZ8cSJiFBP0-crDD2XEzjssBx14Y)

  

GANs generate images given a random vector from latent space. A random walk in this latent space changes the generated image in a meaningful way. This shows the relationship between this vector and the semantics of the generated image. In ongoing work, Bolei Zhou et all. showed that it is, in fact, possible to classify latent space according to attributes. For example, one can find the boundary of latent space to turn indoor lights on/off.

  

The third question was, can we use GAN to reconstruct an image i.e. given an image $x$, can we find its latent space $z$ such that GAN can reproduce the original image $x$? While GAN can reconstruct images, the generated image turns out to be different from the original as shown in the figure.

  

![enter image description here](https://lh3.googleusercontent.com/uOLADqFIBAWAvXTEXYCdFNq-AH0bvmXOvcBZOzGS28eVrrmPDYdAI6OKxg-tnmY0wMxKBqBBazs)

  

As shown in the paper [14], GAN doesn't like generating many objects such as people, vehicles, signs, etc. Similarly, given an Asian face, GANs tend to make it white. Does this show the limitations and biases of the GAN?

  

After the talk, I was able to ask a few questions from Zhou. One question that came to my mind from the Asian face to the Whiteface phenomenon is what is the root of issues in reconstruction; data or GAN? To me, it seems like a data rather than a GAN problem.

  

The third and last talk of the session and the day [Explaining deep learning for identifying structures and biases in computer vision](https://interpretablevision.github.io/slide/iccv19_binder_slide.pdf) by [Prof. Alexander Binder](https://scholar.google.de/citations?user=5B8CTlEAAAAJ&hl=de). The talk was around the concept of layer-wise relevance propagation (LRP) to interpret neural networks. In this method, the score for each dimension of input is calculated and used as an explanation. This method successfully found game strategies learned by DNN to play atari breakout. He also discussed different ways to find biases in datasets.

  

On the second day of the workshops and tutorials, I decided to take the [Neural Architects](https://neuralarchitects.org/) workshop arranged by the famous VGG group of Oxford University. The first talk was [Neural Architecture and Beyond](https://neuralarchitects.org/slides/zoph-slides.pdf) by [Barret Zoph](http://barretzoph.github.io/). This talk gave a holistic view of progress in the architectures of neural networks and NAS. They divided AI into four periods; good old fashioned where handcrafted features were used without any learning, second when handcrafted features were used with a learning algorithm, and third recent deep learning wave where most of the feature engineering is done at the algorithmic level i.e. change of architecture, etc. and fourth learn to learn or neural architecture search, a recent phenomenon.

![](https://lh3.googleusercontent.com/iH-WJ-K9LFmdx9un13pXTigU_c-5iHifEsFOHvrSq1pwFUAYEym2TDjwqLrUT7Y9cQ8woxrWUBE)

  

While it can be argued that most of the recent benefits in Deep Learning came from improvements in architecture (AlexNet [16], VGG [17], ResNet[18], DenseNet[19], SENet [20], etc. ), this is also one of the most difficult, time-consuming and almost more of an artistic kind of a job. It requires a lot of human effort, intuition, and experimentation. Therefore, this is an ideal task for machine learning i.e. making a neural network to learn the architecture of the neural network. In the modern deep learning era, this was initiated by [21, 22]. Specifically, these papers introduced a reinforcement learning way to find the best architectures. In this setting, a controller proposes an architecture from a search space, this proposed network is trained on a subset of the dataset, then this trained classifier's accuracy and other relevant parameters are fed to the controller as a reward. This way, the controller learned to output the best-performing architecture.

![](https://lh3.googleusercontent.com/Ys4Dwm8OCUmntwFLt6pjjXTN484ckM939msn8l4HDEISShUXqpHxFP-R2YqdOp2k-SqES5qe2mk)

  

Mostly, an RNN controller is used while search space consists of different architectural elements such as convolution layer, BN layers, connections, etc. Using this way, efficient architecture can be found in almost any field. It has been shown to work in classification, segmentation, video processing, machine translation, and many other tasks as well.

It is also interesting to inspect decisions made by these controllers. While most of the decisions are not very understandable, a few do give interesting insights. For instance, in many of the proposed architectures, more convolution layers are used at the start than at the end.

In recent times, many variants of NAS have been introduced. Platform-aware NAS [23] is used to find an architecture that is both better in accuracy and latency. To achieve this, latency and accuracy-based reward is defined. EffecientNAS [24] solves the challenge of high computations required by NAS by assuming search space as a big graph where each step has multiple options and NAS's job is to find the better path. The neural network selected by the controller is trained for a few steps and weights are shared from previous training.

  

![Effecient NAS](https://lh3.googleusercontent.com/7naqN1DdEGBdmD-UnRIbalFgtUr_leIR-liLZGF7aRt14vDIQ90Ry4IMFmSEQH6GHEKWHbLzeCOW)

  

Similarly, NAS has also been used to find the best data augmentation policy [25]. In this, we try to find three parameters; which operation to perform (rescaling, rotation, etc.), with what probability and magnitude. In [26], the authors found that limiting this search space to find only probability and magnitude also works well.

**[My question](https://youtu.be/O5Rrv6BvdgE?t=1724) for this talk**: Human-devised architectures are very generalizable i.e. an architecture made for classification(Alexnet, Resnet) also works well for many many other tasks. Is it the same for NAS as well? And can we define some notion of overfitting in NAS i.e. if an architecture works well on a task it was found by but fail to work on different tasks? You can hear the question and answer [here](https://youtu.be/O5Rrv6BvdgE?t=1724)

  

The second talk was [Towards General Vision Architectures: Attentive Single-Tasking of Multiple Task]([https://neuralarchitects.org/slides/kokkinos-slides.pdf](https://neuralarchitects.org/slides/kokkinos-slides.pdf)) by [Iasonas Kokkinos](http://www0.cs.ucl.ac.uk/staff/I.Kokkinos/). This talk was about finding a multi-tasking network. To motivate one-network-multiple-tasks, one can see how many things we can extract from one image.

  

![](https://lh3.googleusercontent.com/-sr9IeRlzern8rK37tU1vBpJJYX638rp6rH8OnHn6HY8jOQMe2141NDKrvScThJop0ExXJc-SzU1)

We get a performance boost if we use one network for a few tasks but as the number of tasks increases, the performance decreases. One way to solve this problem is to increase the task-specific processing of the network. But this makes multi-tasking less lucrative as gain in terms of required computations diminishes.

  

We know that multi-tasking does work for some tasks. But to get a full view, we need to get a few things straight. First, some tasks cannot be done via the same network due to task inference [27, 28].

  

![](https://lh3.googleusercontent.com/rhVClpewevhbeDdiajChcC3yExgbq4UhCyXgYIb-_oiQ-6J4nxfyJzUHP22y99QGl78o5N_5BN-9)

  

Similarly, it is even difficult for humans to multi-tasking. To demonstrate this point, one interesting [example](https://www.youtube.com/embed/vJG698U2Mvo) was shown. The solution to this problem, according to him, is to give each task space i.e. divide the network into shared and task-specific spaces.

![](https://lh3.googleusercontent.com/xEP-MVCnvaDvQX9GzyLoG_AR9qkaQWcyX4yGPw6y3vchpuexhJc8qRg78JU6CfNPd8Vkt2RT25uH)

  

One way to do this to first define a general network and then, for each task, find relevant blocks and their connections [29, 30, 31, 32]. The following picture shows one such setting.

![](https://lh3.googleusercontent.com/3JZkO4Fxooj9ZBD1-YZdDLSLKMAltOfOiEf-6jvdMiLcQ1OXrfa5-hUXeWmpITf9NYpE-75YA_O8)

![](https://lh3.googleusercontent.com/VJuhTyUmac5MSLV6CbtaAV8O_uxvx65Ow38CA7jV421cK1qAp2zhQ5cKAZoB8BW8ekfIJ9U5jE-c)

  

But these strategies have a combinatorial search problem. Here comes work done by presenters called attentive single-tasking or multiple tasking[33]. The main aim of the work is to make a network to perform one task at a time instead of multiple in the same forward pass, encourage relevant features and ignore irrelevant features. To do this, they start with an encoder-decoder setup. They made the encoder task-specific and make the decoder learn universal representation. To make the encoder task-specific, the same backbone is used with task-specific attention mechanisms [34] to focus on task-specific features while ignoring task-irrelevant features, task-specific residual adapters [35], and on top of the network, an adversarial task discriminator. These additional layers keep 95% of the network shared while also creating task-specific space.

![](https://lh3.googleusercontent.com/-wLSA6cpHR10mauif1c9CDcFMFHo6E9fkUWRL7tgjnSaSETL85gL0h6z_Zkd3a-T0M30FZW35EnD)

  
### Poster Presentation of Our Paper

On the last day of the conference, I presented our paper in the workshop on computational imaging. This paper was a collaboration with my ex. colleagues from [Spider Lab](http://spider.itu.edu.pk/).

<a href='https://photos.google.com/share/AF1QipO1y7ZDgQRKNfv4rygaktKBG1KSj5_MLCOxHdAtl0kI3WvhclngAXVNbOJodydf_w?key=Y0dELWE3MllvaUdPWFAtdEZoRGNtSThneXh4SmN3&source=ctrlq.org'><img src='https://lh3.googleusercontent.com/KmxaxGALzTjnxjV4m4iLM8Iw9yf7JeMZnZ5EVHiZpB38iUJwhCHnK5KE6YnyWdDD04NPKhXqLzL7rxe9NG-0dd5m1PmlKCYgNHcYLhlgqKZyOUY5NJ8-9Ap2O0ZFj17-wAfPp6U6JA=w2400' /></a>

  

  

### Interesting Papers

- SinGAN: Learning a Generative Model from a Single Natural Image
- Why Does Data-Driven Beat Theory-Driven Computer Vision?
- GeoStyle: Discovering Fashion Trends and Events
- Symmetric Cross-Entropy for Robust Learning with Noisy Labels
- NLNL: Negative Learning for Noisy Labels
- Adversarial Robustness vs. Model Compression, or Both?
- What Else Can Fool Deep Learning? Addressing Color Constancy Errors on Deep Neural Network Performance
- Exploring Randomly Wired Neural Networks for Image Recognition
- Exploring Randomly Wired Neural Networks for Image Recognition
- Transferability and Hardness of Supervised Classification Tasks
- Switchable Whitening for Deep Representation Learning
- Image Generation From Small Datasets via Batch Statistics Adaptation
- Adversarial Defense by Restricting the Hidden Space of Deep Neural Networks
- EvalNorm: Estimating Batch Normalization Statistics for Evaluation
- Seeing What a GAN Cannot Generate
- Sparse and Imperceivable Adversarial Attacks
- Improving Adversarial Robustness via Guided Complement Entropy
- CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features
- No Fear of the Dark: Image Retrieval Under Varying Illumination Conditions

### Socializing with other Researchers

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Best advice on attending conferences I&#39;ve received.<br><br>Papers &amp; talks are online. The main value is the people. Look up authors/speakers/Twitter in advance to see who&#39;s going and email them asking for a quick chat. Talk to everyone, especially those whose work isn&#39;t already famous.</p>&mdash; Chip Huyen (@chipro) <a href="https://twitter.com/chipro/status/1196889061799055360?ref_src=twsrc%5Etfw">November 19, 2019</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

One of the main attractions of ICCV for me was a chance to meet bigwigs in our community. I use this opportunity to its fullest. Apart from arranging a meetup for Pakistanis attending ICCV, I also had lengthy discussions with many researchers.

- [Prof. Ping Luo](http://luoping.me/): I was following [Prof. Ping Luo](http://luoping.me/) (Hong Kong University, ex-Research director at SenseTime) due to his work on Batch Normalization. Upon my request, he agreed to meet me during the conference to discuss possible internship opportunities with him. It was great talking with him about his research.

- [Prof Mubark Shah](https://www.crcv.ucf.edu/person/mubarak-shah/): Dr. Shah is a very famous professor of computer vision. Since he has been working in this field for a very long and knows conventional cv and has seen neural networks rising so one of the major topics of discussion with him was his views on this change. We also discussed Pakistan since he is a fellow Pakistani.

- [Porf. Nasir Rajpoot](https://warwick.ac.uk/fac/sci/dcs/people/Nasir_Rajpoot/): He is leading Tissue Image Analytics Labs at the University of Warwick. Since he has also witnessed great changes in the field so a major topic of discussion was conventional machine learning in medicine versus deep learning.

- [Dr. Salman Khan](https://salman-h-khan.github.io/): Dr. Salman is a very active computer vision researcher, a lecturer at the Australian National University (ANU), and a Senior Scientist at [Inception Institute of AI](http://www.inceptioniai.org/). I asked him to spare some time and he was kind enough to invite me for lunch. There, we discussed it for 2-3 hours. This was probably one of the best discussions I ever had on artificial intelligence, computer vision, and machine learning. I was impressed with his knowledge of the practical side of deep learning. He gave me really good tips to sharpen up my doing-experiments-quickly skills. We discussed many topics ranging from research to Pakistan, the AI community, and many more. Amazingly, I was able to learn so many things from him even in this short discussion. So, special thanks to him for sparing time for young researchers.

  

- [Dr. Arslan Basharat](https://www.kitware.com/arslan-basharat/): Dr. Basharat is an amazing person to discuss with. One of the major topics of discussion with him was hardships in the life of a graduate student and how to overcome them. He also told us about his work on deep fake detection.

- [Dr. Rao Anwer](https://www.linkedin.com/in/muhammad-anwer-rao-5054106/): Dr. Anwer is a research scientist at the Inception Institute of AI. He is originally from Pakistan so most of the discussion was around Pakistan. 

- [Dr. John K. Tsotsos](http://www.cse.yorku.ca/~tsotsos/Tsotsos/Home.html) on his views on deep learning and its limitations.

- [ Dr. Iasonas Kokkinos](http://www0.cs.ucl.ac.uk/staff/I.Kokkinos/) discussion on multi-tasking neural networks.

- [Dr. Ross Girshick](http://www.rossgirshick.info/) on many general topics like how research is conducted, how suddenly things came out straight from a mess, the stress of the research process, and his work on randomly wired networks.

- [Dr. Bolei Zhou](https://people.csail.mit.edu/bzhou/) on his talk about GANs and his general work on the interpretability of deep learning.

- [Dr. Seong Joon](https://seongjoonoh.com/): Discussed with him his research on the interpretation of deep learning.

 
## Meetup of Pakistanis@ICCV

One of the exciting things at the conference was seeing so many Pakistanis from around the globe attending it. While I met a few, it was not possible to meet everyone. Therefore, I presented the idea of arranging a meet-up with some other young researchers. This was an amazing event attended by around 30 Pakistanis ranging from early researchers to famous professors and researchers like [Prof Mubark Shah](https://www.crcv.ucf.edu/person/mubarak-shah/), Prof. [Porf. Nasir Rajpoot](https://warwick.ac.uk/fac/sci/dcs/people/Nasir_Rajpoot/), [Dr. Arslan Basharat](https://www.kitware.com/arslan-basharat/), [Dr. Salman Khan](https://salman-h-khan.github.io/), Dr. Basharat, and many more. It was an amazing feeling to be able to meet so many accomplished Pakistanis. We end up doing two meetups to accommodate people that were unable to attend the first one.

![](https://lh3.googleusercontent.com/UWatJm9p_eg8pD-Vryc-jaUO7fdqTjvteC9f7_e2h4ZDn3zwepfTMccPDlXKzYANSFY3YO5BB-WY)
 ![](https://lh3.googleusercontent.com/C-5_c_xDIHvfNT1XrC2vG5gf1cPWCyMdbK_6zaY8yaWStV0vzlRPghz1zsYLvU4pYZ97zr21djpB)
 ![](https://lh3.googleusercontent.com/yuZGIiTM7pEP-xBI7MHzDo63Ln9CBjkRFHO0apOhTJmIN2hRPpVdMuwJpPBye_CH0YLgftC3M8SI)
  

## Other moments

|![enter image description here](https://lh3.googleusercontent.com/Qji-rloPLmfxX270-IGBU0j4aOglWNKqSM4uJFBuRsXyruABA56i_TLgSLXT7M7NKOG74SfS7JuQ) | ![enter image description here](https://lh3.googleusercontent.com/OzQBY5s-0yqMb3k1IDOrKVq-5gjR64CxKqNtOVjPbphLfmSm-zwdIsM67HZBzcKTqB9m-jvHEFjd) 
| ![enter image description here](https://lh3.googleusercontent.com/Sbjbdc1ljpT-mupOTL2HaMB3Vf3euP8HEAseRg1GBGQ8_dItOwg--in8NS7N0mDI1faMMgS0UwNx) | ![enter image description here](https://lh3.googleusercontent.com/L9cF6RtpwMbvABAw-uxbtT92ezh6kJ_Mjc1COhNCU0R2Y91dmV3f_bYVCvKji_hzAXI7ICfyD9Si) |
![enter image description here](https://lh3.googleusercontent.com/Hd37onblLq3o1nFh5yIBqiIonVKbONpnNvBOFk7oo9nlRcIiuGMmU9upvHLWJxyZPLe_6Jhocho7) | ![enter image description here](https://lh3.googleusercontent.com/Zdi_b2TNhbxnmpl_tmQeY9w8V3Q3TrWUp3OGZ-iQOZpWCwRlh6V8XvAdGA6ur-_SZbRhfdtIWVq3) |
![enter image description here](https://lh3.googleusercontent.com/xINJJMvJD2NqDa8geC9huuKI9j3E9FCHtMh-MWbXGbJfZzA8YJ2IW5_7FNrQsTvrGiN0-HphExkn) | ![enter image description here](https://lh3.googleusercontent.com/MEJlgTb7ie6Rk-ZWcoZYWEv4QkAEXVC1Ku7JxQGPm4ljszZO_ahoRys-y_vR4U7IFprLcQgHvXDY) |
![enter image description here](https://lh3.googleusercontent.com/AO8Zyu7yRc_SpzbgOyQ3Ij94cWjXRc1DlqsC0EZF9gXqDr2wguQPnEnhcYJK7FFeH2Vi-NwK_TnB)|![enter image description here](https://lh3.googleusercontent.com/KN6BGbnsrQDIOBARoPFC79-9_8G4XXmWPV9-LX5MCWIWAAJDx4EGXC-j0NDqpTBskdm7KbdEmgvT)|

  

  

  

  

  

### References

[1] Gao, Ruiqi, et al. "Learning Grid Cells as Vector Representation of Self-Position Coupled with Matrix Representation of Self-Motion." (2018).

  

[2] Kossaifi, Jean, et al. "T-Net: Parametrizing Fully Convolutional Nets with a Single High-Order Tensor." _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_. 2019.

  

[3] Mahendran, Aravindh, and Andrea Vedaldi. "Understanding deep image representations by inverting them." _Proceedings of the IEEE conference on computer vision and pattern recognition_. 2015.

 
[4] Ulyanov, Dmitry, Andrea Vedaldi, and Victor Lempitsky. "Deep image prior." _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_. 2018.

  

[5] Nguyen, Anh, et al. "Plug & play generative networks: Conditional iterative generation of images in latent space." _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_. 2017.

  

[6] Zeiler, Matthew D., and Rob Fergus. "Visualizing and understanding convolutional networks." _European conference on computer vision_. Springer, Cham, 2014.

  

[7] Simonyan, Karen, Andrea Vedaldi, and Andrew Zisserman. "Deep inside convolutional networks: Visualising image classification models and saliency maps." _arXiv preprint arXiv:1312.6034_ (2013).

  

[8] Springenberg, Jost Tobias, et al. "Striving for simplicity: The all convolutional net." _arXiv preprint arXiv:1412.6806_ (2014).

  

[9] Sundararajan, Mukund, Ankur Taly, and Qiqi Yan. "Axiomatic Attribution for deep networks." _Proceedings of the 34th International Conference on Machine Learning-Volume 70_. JMLR. org, 2017.

  

[10] Zhou, Bolei, et al. "Learning deep features for discriminative localization." _Proceedings of the IEEE conference on computer vision and pattern recognition_. 2016.

  

[11] Selvaraju, Ramprasaath R., et al. "Grad-cam: Visual explanations from deep networks via gradient-based localization." _Proceedings of the IEEE International Conference on Computer Vision_. 2017.

  

[12] Fong, Ruth, Mandela Patrick, and Andrea Vedaldi. "Understanding Deep Networks via Extremal Perturbations and Smooth Masks." _Proceedings of the IEEE International Conference on Computer Vision_. 2019.

  

[13] Bau, David, et al. "Gan dissection: Visualizing and understanding generative adversarial networks." _arXiv preprint arXiv:1811.10597_ (2018).

  

[14] Bau, David, et al. "Seeing What a GAN Cannot Generate." _Proceedings of the IEEE International Conference on Computer Vision_. 2019.

  

[15] Montavon, Grégoire, et al. "Layer-wise relevance propagation: an overview." _Explainable AI: Interpreting, Explaining and Visualizing Deep Learning_. Springer, Cham, 2019. 193-209.

  

[16] Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. "Imagenet classification with deep convolutional neural networks." _Advances in neural information processing systems_. 2012.

  

[17] Simonyan, Karen, and Andrew Zisserman. "Very deep convolutional networks for large-scale image recognition." _arXiv preprint arXiv:1409.1556_ (2014).

  

[18] He, Kaiming, et al. "Deep residual learning for image recognition." _Proceedings of the IEEE conference on computer vision and pattern recognition_. 2016.

  

[19] Huang, Gao, et al. "Densely connected convolutional networks." _Proceedings of the IEEE conference on computer vision and pattern recognition_. 2017.

  

[20] Hu, Jie, Li Shen, and Gang Sun. "Squeeze-and-excitation networks." _Proceedings of the IEEE conference on computer vision and pattern recognition_. 2018.

  

[21] Zoph, Barret, et al. "Learning transferable architectures for scalable image recognition." _Proceedings of the IEEE conference on computer vision and pattern recognition_. 2018.

  

[22] Real, Esteban, et al. "Large-scale evolution of image classifiers." _Proceedings of the 34th International Conference on Machine Learning-Volume 70_. JMLR. org, 2017.

  

[23] Wu, Bichen, et al. "Fbnet: Hardware-aware efficient convnet design via differentiable neural architecture search." _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_. 2019.

  

[24] Pham, Hieu, et al. "Efficient neural architecture search via parameter sharing." _arXiv preprint arXiv:1802.03268_ (2018).

  

[25] Cubuk, Ekin D., et al. "Autoaugment: Learning augmentation policies from data." _arXiv preprint arXiv:1805.09501_ (2018).

  

[26] Cubuk, Ekin D., et al. "RandAugment: Practical data augmentation with no separate search." _arXiv preprint arXiv:1909.13719_ (2019).

  

[27] Kang, Zhuoliang, Kristen Grauman, and Fei Sha. "Learning with Whom to Share in Multi-task Feature Learning." _ICML_. Vol. 2. No. 3. 2011.

  

[28] Romera-Paredes, Bernardino, et al. "Exploiting unrelated tasks in multi-task learning." _International conference on artificial intelligence and statistics_. 2012.

  

[29] Murdock, Calvin, et al. "Blockout: Dynamic model selection for hierarchical deep networks." _Proceedings of the IEEE conference on computer vision and pattern recognition_. 2016.

  

[30] Ahmed, Karim, and Lorenzo Torresani. "Maskconnect: Connectivity learning by gradient descent." _Proceedings of the European Conference on Computer Vision (ECCV)_. 2018.

  

[31] Veniat, Tom, and Ludovic Denoyer. "Learning time/memory-efficient deep architectures with budgeted super networks." _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_. 2018.

  

[32] Fernando, Chrisantha, et al. "Pathnet: Evolution channels gradient descent in super neural networks." _arXiv preprint arXiv:1701.08734_ (2017).

  

[33] Su, Jong-Chyi, Subhransu Maji, and Bharath Hariharan. "When Does Self-supervision Improve Few-shot Learning?." _arXiv preprint arXiv:1910.03560_ (2019).

  

[34] Hu, Jie, Li Shen, and Gang Sun. "Squeeze-and-excitation networks." _Proceedings of the IEEE conference on computer vision and pattern recognition_. 2018.

  

[35] Rebuffi, Sylvestre-Alvise, Hakan Bilen, and Andrea Vedaldi. "Learning multiple visual domains with residual adapters." _Advances in Neural Information Processing Systems_. 2017.

  

[36] [https://medium.com/syncedreview/aaai-2020-reports-record-high-paper-submissions-67f88080c93c](https://medium.com/syncedreview/aaai-2020-reports-record-high-paper-submissions-67f88080c93c)

  

[37] [https://medium.com/syncedreview/cvpr-2019-accepts-record-1300-papers-91b9e3b315f5](https://medium.com/syncedreview/cvpr-2019-accepts-record-1300-papers-91b9e3b315f5)
